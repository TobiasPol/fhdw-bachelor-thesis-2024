@article{AccuracyPrecision2024,
  title = {Accuracy and Precision},
  year = {2024},
  month = apr,
  journal = {Wikipedia},
  urldate = {2024-05-31},
  abstract = {Accuracy and precision are two measures of observational error. Accuracy is how close a given set of measurements (observations or readings) are to their true value. Precision is how close the measurements are to each other. In other words: Precision is a description of random errors (a measure of statistical variability). Accuracy has two definitions, per ISO: More commonly, a description of systematic errors (a measure of statistical bias of a given measure of central tendency). Low accuracy causes a difference between a result and a true value. This secondary measure is referred to as trueness by ISO. A combination of both types of observational error (random and systematic), so high accuracy requires both high precision and high trueness. In the first, more common definition of "accuracy" above, the concept is independent of "precision", so a particular set of data can be said to be accurate, precise, both, or neither. In simpler terms, given a statistical sample or set of data points from repeated measurements of the same quantity, the sample or set can be said to be accurate if their average is close to the true value of the quantity being measured, while the set can be said to be precise if their standard deviation is relatively small.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1220739681}
}

@article{belloTheoreticalApproachMechanism2000,
  title = {A Theoretical Approach to the Mechanism of Biological Oxidation of Organophosphorus Pesticides},
  author = {Bello, Angelica and Carreon, Yessica and {Nava-Ocampo}, Alejandro},
  year = {2000},
  month = aug,
  journal = {Toxicology},
  volume = {149},
  pages = {63--8},
  doi = {10.1016/S0300-483X(00)00222-5},
  abstract = {Organophosphorus pesticides are the most common classes involved in poisonings related to pesticides. We used enzymatic activity of chloroperoxidase on the metabolism of some phosphorothioate pesticides published previously and molecular mechanics methods to perform a theoretical approach of the mechanism of biological oxidation of this class of pesticides. The molecular structure of eight pesticides were optimized by molecular mechanics methods using the CAChe program package for biomolecules, ver. 3.11 (Oxford Molecular Ltd., Campbell, CA). Total energy resulted from the structure optimization process and the partial charges of both phosphorus and sulfur were computed for every pesticide. Phosphorus partial charge and enzymatic activity were significantly related by linear regression analysis (r=0.82, P{$<$}0.05). Analyzing our results and using previously reported enzymatic activity of chloroperoxidase on these pesticides, we deduced chemical events involved in activation of the active site of chloroperoxidase and proposed a novel mechanism of oxidation for this class of pesticides. This mechanism will also help to understand the oxidation process of pesticides by cytochrome P450, and production of toxic metabolites.}
}

@misc{DeEPnDeepNeural,
  title = {{{DeEPn}}: A Deep Neural Network Based Tool for Enzyme Functional Annotation - {{Consensus}}},
  urldate = {2024-05-29},
  howpublished = {https://consensus.app/papers/deepn-network-based-tool-annotation-semwal/c62a6c023f2d5b2f9348b36f6329daae/?utm\_source=chatgpt}
}

@article{emmert-streibIntroductoryReviewDeep2020,
  title = {An {{Introductory Review}} of {{Deep Learning}} for {{Prediction Models With Big Data}}},
  author = {{Emmert-Streib}, F. and Yang, Zhenyi and Feng, Han and Tripathi, S. and Dehmer, M.},
  year = {2020},
  journal = {Frontiers in Artificial Intelligence},
  volume = {3},
  doi = {10.3389/frai.2020.00004},
  urldate = {2024-05-31},
  abstract = {Deep learning models stand for a new learning paradigm in artificial intelligence (AI) and machine learning. Recent breakthrough results in image analysis and speech recognition have generated a massive interest in this field because also applications in many other domains providing big data seem possible. On a downside, the mathematical and computational methodology underlying deep learning models is very challenging, especially for interdisciplinary scientists. For this reason, we present in this paper an introductory review of deep learning approaches including Deep Feedforward Neural Networks (D-FFNN), Convolutional Neural Networks (CNNs), Deep Belief Networks (DBNs), Autoencoders (AEs), and Long Short-Term Memory (LSTM) networks. These models form the major core architectures of deep learning models currently used and should belong in any data scientist's toolbox. Importantly, those core architectural building blocks can be composed flexibly---in an almost Lego-like manner---to build new application-specific network architectures. Hence, a basic understanding of these network architectures is important to be prepared for future developments in AI.},
  file = {/Users/tobias.polley/Zotero/storage/5856BVP6/Emmert-Streib et al. - 2020 - An Introductory Review of Deep Learning for Predic.pdf}
}

@misc{EnzymesPrinciplesBiotechnological,
  title = {Enzymes: Principles and Biotechnological Applications - {{Consensus}}},
  urldate = {2024-05-30},
  howpublished = {https://consensus.app/papers/enzymes-principles-applications-robinson/ae03e77090335664b83066824731b95f/?utm\_source=chatgpt}
}

@article{Fscore2024,
  title = {F-Score},
  year = {2024},
  month = may,
  journal = {Wikipedia},
  urldate = {2024-05-31},
  abstract = {In statistical analysis of binary classification and information retrieval systems, the F-score or F-measure is a measure of predictive performance. It is calculated from the precision and recall of the test, where the precision is the number of true positive results divided by the number of all samples predicted to be positive, including those not identified correctly, and the recall is the number of true positive results divided by the number of all samples that should have been identified as positive. Precision is also known as positive predictive value, and recall is also known as sensitivity in diagnostic binary classification. The F1 score is the harmonic mean of the precision and recall. It thus symmetrically represents both precision and recall in one metric. The more generic                                    F                        {$\beta$}                                     \{{\textbackslash}displaystyle F\_\{{\textbackslash}beta \}\}     score applies additional weights, valuing one of precision or recall more than the other. The highest possible value of an F-score is 1.0, indicating perfect precision and recall, and the lowest possible value is 0, if precision and recall are zero.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1225870376}
}

@article{fuDegradationPesticidesDiazinon2021,
  title = {Degradation of Pesticides Diazinon and Diazoxon by Phosphotriesterase: Insight into Divergent Mechanisms from {{QM}}/{{MM}} and {{MD}} Simulations.},
  shorttitle = {Degradation of Pesticides Diazinon and Diazoxon by Phosphotriesterase},
  author = {Fu, Yuzhuang and Zhang, Yuwei and Fan, Fangfang and Wang, Binju and Cao, Z.},
  year = {2021},
  journal = {Physical chemistry chemical physics : PCCP},
  doi = {10.1039/d1cp05034f},
  urldate = {2024-05-29},
  abstract = {Enzymatic hydrolysis by phosphotriesterase (PTE) is one of the most effective ways of degrading organophosphorus pesticides, but the catalytic efficiency depends on the structural features of substrates. Here the enzymatic degradation of diazinon (DIN) and diazoxon (DON), characterized by PS and PO, respectively, have been investigated by QM/MM calculations and MM MD simulations. Our calculations demonstrate that the hydrolysis of DON (with PO) is inevitably initiated by the nucleophilic attack of the bridging-OH- on the phosphorus center, while for DIN (with PS), we proposed a new degradation mechanism, initiated by the nucleophilic attack of the Zn{$\alpha$}-bound water molecule, for its low-energy pathway. For both DIN and DON, the hydrolytic reaction is predicted to be the rate-limiting step, with energy barriers of 18.5 and 17.7 kcal mol-1, respectively. The transportation of substrates to the active site, the release of the leaving group and the degraded product are generally verified to be favorable by MD simulations via umbrella sampling, both thermodynamically and dynamically. The side-chain residues Phe132, Leu271 and Tyr309 play the gate-switching role to manipulate substrate delivery and product release. In comparison with the DON-enzyme system, the degraded product of DIN is more easily released from the active site. These new findings will contribute to the comprehensive understanding of the enzymatic degradation of toxic organophosphorus compounds by PTE.}
}

@article{krivakP2RankMachineLearning2018,
  title = {{{P2Rank}}: Machine Learning Based Tool for Rapid and Accurate Prediction of Ligand Binding Sites from Protein Structure},
  shorttitle = {{{P2Rank}}},
  author = {Kriv{\'a}k, Radoslav and Hoksza, David},
  year = {2018},
  month = aug,
  journal = {Journal of Cheminformatics},
  volume = {10},
  number = {1},
  pages = {39},
  issn = {1758-2946},
  doi = {10.1186/s13321-018-0285-8},
  urldate = {2024-05-29},
  abstract = {Ligand binding site prediction from protein structure has many applications related to elucidation of protein function and structure based drug discovery. It often represents only one step of many in complex computational drug design efforts. Although many methods have been published to date, only few of them are suitable for use in automated pipelines or for processing large datasets. These use cases require stability and speed, which disqualifies many of the recently introduced tools that are either template based or available only as web servers.},
  keywords = {Binding site prediction,Ligand binding sites,Machine learning,Protein pockets,Protein surface descriptors,Random forests},
  file = {/Users/tobias.polley/Zotero/storage/DPUM26V8/Krivák and Hoksza - 2018 - P2Rank machine learning based tool for rapid and .pdf;/Users/tobias.polley/Zotero/storage/VX3GIXPD/s13321-018-0285-8.html}
}

@article{lecunDeepLearning2015,
  title = {Deep Learning},
  author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  year = {2015},
  month = may,
  journal = {Nature},
  volume = {521},
  number = {7553},
  pages = {436--444},
  publisher = {Nature Publishing Group},
  issn = {1476-4687},
  doi = {10.1038/nature14539},
  urldate = {2024-05-16},
  abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
  copyright = {2015 Springer Nature Limited},
  langid = {english},
  keywords = {Computer science,Mathematics and computing},
  file = {/Users/tobias.polley/Zotero/storage/JELDQMA8/LeCun et al. - 2015 - Deep learning.pdf}
}

@article{liDEEPreSequencebasedEnzyme2017,
  title = {{{DEEPre}}: Sequence-Based Enzyme {{EC}} Number Prediction by Deep Learning},
  shorttitle = {{{DEEPre}}},
  author = {Li, Yu and Wang, Sheng and Umarov, Ramzan and Xie, Bingqing and Fan, M. and Li, Lihua and Gao, Xin},
  year = {2017},
  journal = {Bioinformatics},
  volume = {34},
  pages = {760--769},
  doi = {10.1093/bioinformatics/btx680},
  urldate = {2024-05-29},
  abstract = {Motivation Annotation of enzyme function has a broad range of applications, such as metagenomics, industrial biotechnology, and diagnosis of enzyme deficiency-caused diseases. However, the time and resource required make it prohibitively expensive to experimentally determine the function of every enzyme. Therefore, computational enzyme function prediction has become increasingly important. In this paper, we develop such an approach, determining the enzyme function by predicting the Enzyme Commission number. Results We propose an end-to-end feature selection and classification model training approach, as well as an automatic and robust feature dimensionality uniformization method, DEEPre, in the field of enzyme function prediction. Instead of extracting manually crafted features from enzyme sequences, our model takes the raw sequence encoding as inputs, extracting convolutional and sequential features from the raw encoding based on the classification result to directly improve the prediction performance. The thorough cross-fold validation experiments conducted on two large-scale datasets show that DEEPre improves the prediction performance over the previous state-of-the-art methods. In addition, our server outperforms five other servers in determining the main class of enzymes on a separate low-homology dataset. Two case studies demonstrate DEEPre's ability to capture the functional difference of enzyme isoforms. Availability and implementation The server could be accessed freely at http://www.cbrc.kaust.edu.sa/DEEPre. Contact xin.gao@kaust.edu.sa Supplementary information Supplementary data are available at Bioinformatics online.},
  file = {/Users/tobias.polley/Zotero/storage/DUKBWBT8/Li et al. - 2017 - DEEPre sequence-based enzyme EC number prediction.pdf}
}

@article{munneckeEnzymaticHydrolysisOrganophosphate1976,
  title = {Enzymatic Hydrolysis of Organophosphate Insecticides, a Possible Pesticide Disposal Method},
  author = {Munnecke, D.},
  year = {1976},
  journal = {Applied and Environmental Microbiology},
  volume = {32},
  pages = {7--13},
  doi = {10.1128/aem.32.1.7-13.1976},
  urldate = {2024-05-29},
  abstract = {A crude cell extract from a mixed bacterial culture growing on parathion, an organophosphate insecticide, hydrolyzed parathion (21 C) at a rate of 416 nmol/min per mg of protein. This rate of enzymatic hydrolysis, when compared with chemical hydrolysis by 0.1 N sodium hydroxide at 40 C, was 2, 450 times faster. Eight of 12 commonly used organophosphate insecticides were enzymatically hydrolyzed with this enzyme preparation at rates ranging from 12 to 1,360 nmol/min per mg of protein. Seven pesticides were hydrolyzed at rates significantly higher (40 to 1,005 times faster) than chemical hydrolysis. The pH optimum for enzymatic hydrolysis of the eight pesticides ranged from 8.5 to 9.5, with less than 50\% of maximal activity expressed at pH 7.0. Maximal enzyme activity occurred at 35 C. The crude extract lost its activity at the rate of only 0.75\%/day when stored at 6 C. Eight organic solvents, ranging from methanol to hexane, at low concentrations stimulated enzymatic hydrolysis by 3 to 20\%, whereas at higher concentrations (1,000 mg/liter) they inhibited the reaction (9 to 50\%). Parathion metabolites p-nitrophenol, hydroquinone, and diethylthiophosphoric acid, at up to 100-mg/liter concentrations, did not significantly influence enzyme activity.},
  file = {/Users/tobias.polley/Zotero/storage/BPHKNKTY/Munnecke - 1976 - Enzymatic hydrolysis of organophosphate insecticid.pdf}
}

@article{munneckeEnzymaticHydrolysisOrganophosphate1976a,
  title = {Enzymatic Hydrolysis of Organophosphate Insecticides, a Possible Pesticide Disposal Method},
  author = {Munnecke, D.},
  year = {1976},
  journal = {Applied and Environmental Microbiology},
  volume = {32},
  pages = {7--13},
  doi = {10.1128/aem.32.1.7-13.1976},
  urldate = {2024-05-30},
  abstract = {A crude cell extract from a mixed bacterial culture growing on parathion, an organophosphate insecticide, hydrolyzed parathion (21 C) at a rate of 416 nmol/min per mg of protein. This rate of enzymatic hydrolysis, when compared with chemical hydrolysis by 0.1 N sodium hydroxide at 40 C, was 2, 450 times faster. Eight of 12 commonly used organophosphate insecticides were enzymatically hydrolyzed with this enzyme preparation at rates ranging from 12 to 1,360 nmol/min per mg of protein. Seven pesticides were hydrolyzed at rates significantly higher (40 to 1,005 times faster) than chemical hydrolysis. The pH optimum for enzymatic hydrolysis of the eight pesticides ranged from 8.5 to 9.5, with less than 50\% of maximal activity expressed at pH 7.0. Maximal enzyme activity occurred at 35 C. The crude extract lost its activity at the rate of only 0.75\%/day when stored at 6 C. Eight organic solvents, ranging from methanol to hexane, at low concentrations stimulated enzymatic hydrolysis by 3 to 20\%, whereas at higher concentrations (1,000 mg/liter) they inhibited the reaction (9 to 50\%). Parathion metabolites p-nitrophenol, hydroquinone, and diethylthiophosphoric acid, at up to 100-mg/liter concentrations, did not significantly influence enzyme activity.},
  file = {/Users/tobias.polley/Zotero/storage/X4NSVEW5/Munnecke - 1976 - Enzymatic hydrolysis of organophosphate insecticid.pdf}
}

@article{murugesanDeepCompareVisualInteractive2019,
  title = {{{DeepCompare}}: {{Visual}} and {{Interactive Comparison}} of {{Deep Learning Model Performance}}},
  shorttitle = {{{DeepCompare}}},
  author = {Murugesan, Sugeerth and Malik, Sana and Du, F. and Koh, Eunyee and Lai, T.},
  year = {2019},
  journal = {IEEE Computer Graphics and Applications},
  volume = {39},
  pages = {47--59},
  doi = {10.1109/MCG.2019.2919033},
  urldate = {2024-05-31},
  abstract = {Deep learning models have become the state-of-the-art for many tasks, from text sentiment analysis to facial image recognition. However, understanding why certain models perform better than others or how one model learns differently than another is often difficult yet critical for increasing their effectiveness, improving prediction accuracy, and enabling fairness. Traditional methods for comparing models' efficacy, such as accuracy, precision, and recall provide a quantitative view of performance; however, the qualitative intricacies of why one model performs better than another are hidden. In this paper, we interview machine learning practitioners to understand their evaluation and comparison workflow. From there, we iteratively design a visual analytic approach, DeepCompare, to systematically compare the results of deep learning models, in order to provide insight into the model behavior and interactively assess tradeoffs between two such models. The tool allows users to evaluate model results, identify and compare activation patterns for misclassifications, and link the test results back to specific neurons. We conduct a preliminary evaluation through two real-world case studies to show that experts can make more informed decisions about the effectiveness of different types of models, understand in more detail the strengths and weaknesses of the models, and holistically evaluate the behavior of the models.}
}

@article{PrecisionRecall2024,
  title = {Precision and Recall},
  year = {2024},
  month = apr,
  journal = {Wikipedia},
  urldate = {2024-05-31},
  abstract = {In pattern recognition, information retrieval, object detection and classification (machine learning), precision and recall are performance metrics that apply to data retrieved from a collection, corpus or sample space. Precision (also called positive predictive value) is the fraction of relevant instances among the retrieved instances. Written as a formula: Recall (also known as sensitivity) is the fraction of relevant instances that were retrieved. Written as a formula: Both precision and recall are therefore based on relevance.  Consider a computer program for recognizing dogs (the relevant element) in a digital photograph. Upon processing a picture which contains ten cats and twelve dogs, the program identifies eight dogs. Of the eight elements identified as dogs, only five actually are dogs (true positives), while the other three are cats (false positives). Seven dogs were missed (false negatives), and seven cats were correctly excluded (true negatives). The program's precision is then 5/8 (true positives / selected elements) while its recall is 5/12 (true positives / relevant elements). Adopting a hypothesis-testing approach from statistics, in which, in this case, the null hypothesis is that a given item is irrelevant (i.e., not a dog), absence of type I and type II errors (i.e., perfect specificity and sensitivity of 100\% each) corresponds respectively to perfect precision (no false positive) and perfect recall (no false negative).   More generally, recall is simply the complement of the type II error rate (i.e., one minus the type II error rate). Precision is related to the type I error rate, but in a slightly more complicated way, as it also depends upon the prior distribution of seeing a relevant vs. an irrelevant item. The above cat and dog example contained 8 - 5 = 3 type I errors (false positives) out of 10 total cats (true negatives), for a type I error rate of 3/10, and 12 - 5 = 7 type II errors (false negatives), for a type II error rate of 7/12.  Precision can be seen as a measure of quality, and recall as a measure of quantity.  Higher precision means that an algorithm returns more relevant results than irrelevant ones, and high recall means that an algorithm returns most of the relevant results (whether or not irrelevant ones are also returned).},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1220938692}
}

@article{ReceiverOperatingCharacteristic2024,
  title = {Receiver Operating Characteristic},
  year = {2024},
  month = may,
  journal = {Wikipedia},
  urldate = {2024-05-31},
  abstract = {A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the performance of a binary classifier model (can be used for multi class classification as well) at varying threshold values. The ROC curve is the plot of the true positive rate (TPR) against the false positive rate (FPR) at each threshold setting. The ROC can also be thought of as a plot of the statistical power as a function of the Type I Error of the decision rule (when the performance is calculated from just a sample of the population, it can be thought of as estimators of these quantities). The ROC curve is thus the sensitivity or recall as a function of false positive rate. Given the probability distributions for both true positive and false positive are known, the ROC curve is obtained as the cumulative distribution function (CDF, area under the probability distribution from                         -         {$\infty$}                 \{{\textbackslash}displaystyle -{\textbackslash}infty \}     to the discrimination threshold) of the detection probability in the y-axis versus the CDF of the false positive probability on the x-axis. ROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic decision making.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1226127318}
}

@article{veselovskyApproachVisualizationActive2001,
  title = {An {{Approach}} for {{Visualization}} of the {{Active Site}} of {{Enzymes}} with {{Unknown Three-Dimensional Structures}}},
  author = {Veselovsky, A. and Tikhonova, O. and Skvortsov, Vladlen S. and Medvedev, A. and Ivanov, A. S.},
  year = {2001},
  journal = {SAR and QSAR in Environmental Research},
  volume = {12},
  pages = {345--358},
  doi = {10.1080/10629360108033243},
  urldate = {2024-05-30},
  abstract = {Abstract A new approach for virtual characterization of the active site structure of enzymes with unknown three-dimensional (3D) structure has been proposed. It includes analysis of data on enzyme interaction with reversible competitive inhibitors, their 3D structures and moulding of the substrate-binding region. The superposition of ligands in biologically active conformations allows to determine the shape and dimension of the active site cavity accommodating these compounds. Monoamine oxidase A (MAO-A), a ``typical'' enzyme with unknown spatial organisation, was used to test this method. The correctness of such approach was validated by the analysis of HIV protease interaction with its inhibitors using 3D structures of their complexes. Mould of the substrate/inhibitor binding site can be used for the visualization of this binding site and for searching new ligands in molecular databases.},
  file = {/Users/tobias.polley/Zotero/storage/CUSMC9WJ/b12c36ed3fa05b34aff7f6c416fd1730.html}
}
